{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport re\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport math\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\n\n\nfrom kaggle_datasets import KaggleDatasets","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":2,"outputs":[{"output_type":"stream","text":"REPLICAS:  1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_PATH = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n\n# Configuration\nEPOCHS = 12\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [1024, 1024]\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_path(pre):\n    return np.vectorize(lambda file: os.path.join(GCS_DS_PATH, pre, file))","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the training and sample submission files\n\nsub = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['target'])","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f7c500c2750>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the training and testing filenames\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/train*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/tfrecords/test*.tfrec')\n\nCLASSES = [0,1]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Lets look at how the training file names look like\nTRAINING_FILENAMES[:3]","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"['gs://kds-599205fd0d8963558ce1308147ba090f776d31b1662a67f2ddccfa38/tfrecords/train00-2071.tfrec',\n 'gs://kds-599205fd0d8963558ce1308147ba090f776d31b1662a67f2ddccfa38/tfrecords/train01-2071.tfrec',\n 'gs://kds-599205fd0d8963558ce1308147ba090f776d31b1662a67f2ddccfa38/tfrecords/train02-2071.tfrec']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef decode_image(image_data):\n    image =  tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\n\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string),\n        \"target\" : tf.io.FixedLenFeature([], tf.int64)\n    }\n    \n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['target'], tf.int32)\n    return image, label\n\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string),\n        \"image_name\" : tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    id_num = example['image_name']\n    return image, id_num\n    \n    \ndef load_dataset(filenames, labeled = True, ordered = False):\n    \n    # disregarding  the  data order\n    ignore_order = tf.data.Options()\n    \n    if not ordered:\n        # disabling the order to increase speed\n        ignore_order.experimental_deterministic = False\n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO) #automatically reads from different files\n    dataset =  dataset.with_options(ignore_order) # reads dataset as it comes in rather than its original order\n    \n    # returns a dataset of (image,  label) if labele is true else returns (image, id) if unlabeled\n    dataset  = dataset.map(read_labeled_tfrecord if  labeled else read_unlabeled_tfrecord,\n                           num_parallel_calls = AUTO)\n    \n    return dataset\n\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    return image, label\n\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled = True)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.repeat() # the training  dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch the next batch while training (autotune prefetch buffer size)\n    return dataset\n\n\ndef get_validation_dataset(ordered = False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled = True, ordered = ordered)\n    dataset =  dataset.batch(BATCH_SIZE)\n    dataset =  dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch the next batch while training (autotune prefetch buffer size)\n    return dataset\n    \n    \n    \ndef get_test_dataset(ordered = False):\n    dataset = load_dataset(TEST_FILENAMES, labeled = False, ordered = ordered)\n    dataset =  dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch the next batch while training (autotune prefetch buffer size)\n    return dataset\n    \n    \n    \ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n    \n    \n    \nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nprint('Dataset: {} training images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_TEST_IMAGES))","execution_count":22,"outputs":[{"output_type":"stream","text":"Dataset: 33126 training images, 10982 unlabeled test images\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([\n        tf.keras.applications.ResNet50(\n            weights =  'imagenet',\n            input_shape  = [*IMAGE_SIZE, 3],\n            include_top =  False\n        ),\n        L.GlobalAveragePooling2D(),\n        L.Dense(1024, activation = 'relu'), \n        L.Dropout(0.3), \n        L.Dense(512, activation= 'relu'), \n        L.Dropout(0.2), \n        L.Dense(256, activation='relu'), \n        L.Dropout(0.2), \n        L.Dense(128, activation='relu'), \n        L.Dropout(0.1), \n        L.Dense(1, activation='sigmoid')\n        \n    ]) \n    \n    \nmodel.compile(loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.1),\n             metrics = ['accuracy'],\n             optimizer =  'adam')\n\nmodel.summary()\n    \n    ","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 32, 32, 2048)      23587712  \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 2048)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1024)              2098176   \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 26,375,041\nTrainable params: 26,321,921\nNon-trainable params: 53,120\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n\nhistory = model.fit(\n            get_training_dataset(),\n            epochs = EPOCHS,\n            steps_per_epoch = STEPS_PER_EPOCH,\n            verbose= 1\n)","execution_count":23,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"in user code:\n\n    <ipython-input-20-45cd845e23c5>:16 read_labeled_tfrecord  *\n        image = decode_image(example['image'])\n    <ipython-input-20-45cd845e23c5>:2 decode_image  *\n        image =  tf.image.decode_jpg(image_data, channels = 3)\n\n    AttributeError: module 'tensorflow._api.v2.image' has no attribute 'decode_jpg'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-953743d4bc6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit(\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-45cd845e23c5>\u001b[0m in \u001b[0;36mget_training_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_FILENAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_augment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the training  dataset must repeat for several epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-45cd845e23c5>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(filenames, labeled, ordered)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# returns a dataset of (image,  label) if labele is true else returns (image, id) if unlabeled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     dataset  = dataset.map(read_labeled_tfrecord if  labeled else read_unlabeled_tfrecord,\n\u001b[0;32m---> 46\u001b[0;31m                            num_parallel_calls = AUTO)\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1626\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m           preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4018\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4019\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4020\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4021\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4022\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[1;32m   2531\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2532\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3212\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3213\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3214\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3215\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3154\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3156\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3157\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-20-45cd845e23c5>:16 read_labeled_tfrecord  *\n        image = decode_image(example['image'])\n    <ipython-input-20-45cd845e23c5>:2 decode_image  *\n        image =  tf.image.decode_jpg(image_data, channels = 3)\n\n    AttributeError: module 'tensorflow._api.v2.image' has no attribute 'decode_jpg'\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}